<h1>Capstone Proposal</h1>
<h2>Language Detection Using Audio Data</h2>
<h3>Proposed by: Jack McMorrow and Carrie Magee</h3>
<h4>Email: jmcmorrow@gwu.edu, mageec@gwu.edu</h4>
<h4>Advisor: Edwin Lo</h4>
<h4>The George Washington University, Washington DC</h4>
<h4>Data Science Program</h4>
<h2>1 Objective:</h2>
<pre><code>        The objective of the project is to develop a language detection program using the Common Voice dataset. This dataset 
        contains a collection of speech recordings covering a range of languages, accents, and dialects. Using this extensive 
        dataset, our project aims to create a program that can accurately identify which language a human is speaking based on 
        various types of speech recordings. This type of project is crucial for facilitating communication across different 
        language barriers by being able to detect and transcribe various languages.
</code></pre>
<p><img src="202401_001.png" alt="Figure 1: Example figure">
<em>Figure 1: Caption</em></p>
<h2>2 Dataset:</h2>
<pre><code>        As mentioned above, we will be using data from the Common Voice dataset created by Mozilla. The dataset is publicly 
        available and contains audio recordings of various human voices. Recordings are done by volunteers and the database 
        contains recordings of over 50 languages. 
</code></pre>
<h2>3 Rationale:</h2>
<pre><code>        By developing a language detection program, we hope to tackle linguistic barriers and promote effective communication 
        within our interconnected global communities. The first step to breaking this barrier is to develop a program that has 
        the ability to detect a language by speech alone. 
</code></pre>
<h2>4 Approach:</h2>
<pre><code>        To approach a problem like this, we will have to use deep learning techniques such as neural networks to develop an 
        effective model. Convolutional neural networks, which are effective for image recognition problems, can also be very 
        effective when working with audio data. We believe that these types of networks will work well when classifying audio 
        data. We are also open to exploring different network structures. 
</code></pre>
<h2>5 Timeline:</h2>
<pre><code>        Jan 29: Proposal
        Feb 5: Elevator pitch
        Feb 12: EDA and research on NN with audio data
        Feb 19: Preliminary network design
        Feb 26: Continue with network design
        March 4: Fine tuning network
        April 15: Mock Presentation
        April 22: Mock Presentation
        April 29: Poster session
        May 3: Video Presentation
        May 6: Final report due
</code></pre>
<h2>6 Expected Number Students:</h2>
<pre><code>        There will be 2 students working on this project: Carrie Magee and Jack McMorrow.  
</code></pre>
<h2>7 Possible Issues:</h2>
<pre><code>        Considering the recordings are conducted on a voluntary basis, the dataset lacks representation of various language 
        groups. Therefore, the program may not perform equally on every individual voice. Other technical issues could include 
        the management and storage of the dataset.
</code></pre>
<h2>Contact</h2>
<ul>
<li>Author: Edwin Lo</li>
<li>Email: <a href="Eamil">edwinlo@gwu.edu</a></li>
<li>GitHub: <a href="Git Hub rep">https://github.com/amir-jafari/Capstone</a></li>
</ul>
